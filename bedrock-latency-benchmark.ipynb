{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0547b7e-8934-431c-8527-7c0175766bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade boto3 awscli matplotlib numpy pandas anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c18653-9acf-4aa5-9800-76dadb55a338",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Benchmark latency for Amazon Bedrock models\n",
    "Notes:\n",
    "1. This benchmark tests can test for either complete responses or streaming responses.\n",
    "2. Latency will possibly be lower when using provisioned throughput (currently using on-demand). See: TODO\n",
    "3. Using boto3 Bedrock API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201e7b19-7c12-4d8a-a8b3-0fc792cec9d5",
   "metadata": {},
   "source": [
    "Test Amazon Bedrock setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b8b11d-f238-48cd-b5d3-04800c0f53af",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TODO add configuration section\n",
    "-- Streaming | complete responses\n",
    "-- Boto3 retries - should be 0 normally\n",
    "-- models to test\n",
    "-- Input tokens\n",
    "-- Output toekns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea26029-457a-4193-ab9f-b30e8020a1fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3, botocore\n",
    "bedrock = boto3.client(service_name='bedrock-runtime', \n",
    "                       config=botocore.config.Config(retries=dict(max_attempts=0))) # prevent auto retries so we're measuring a single transcation\n",
    "#print(bedrock.list_foundation_models())\n",
    "#bedrock.get_foundation_model(modelIdentifier='anthropic.claude-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de0334e0-8f20-4566-84e3-8a4e857a2e2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic() # used to count tokens only\n",
    "\n",
    "# This prompt should include arbitrary long input and generate arbitrary long output\n",
    "def _get_prompt_template(num_input_tokens):\n",
    "    tokens = 'Human:'\n",
    "    tokens += 'Ignore X' + '<X>'\n",
    "    for i in range(num_input_tokens-1):\n",
    "        tokens += random.choice(['hello', 'world', 'foo', 'bar']) + ' '\n",
    "    tokens += '</X>'\n",
    "    tokens += \"print numbers 1 to 9999 as words. don't omit for brevity\"\n",
    "    tokens += '\\n\\nAssistant:one two'  # model will continue with \" three four five...\"\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# This method will return a prompt template with the given expected_num_tokens that cause the model to generate up to 10K tokens in response\n",
    "def get_text_tokens(expected_num_tokens):\n",
    "    num_tokens_in_prompt_template = client.count_tokens(_get_prompt_template(0))\n",
    "    additional_tokens_needed = max(expected_num_tokens - num_tokens_in_prompt_template,0)\n",
    "    \n",
    "    prompt_template = _get_prompt_template(additional_tokens_needed)\n",
    "    \n",
    "    actual_num_tokens = client.count_tokens(prompt_template)\n",
    "    #print(f'expected_num_tokens={expected_num_tokens}, actual_tokens={actual_num_tokens}')\n",
    "    assert expected_num_tokens==actual_num_tokens, f'Failed to generate prompt at required length: expected_num_tokens{expected_num_tokens} != actual_num_tokens={actual_num_tokens}'\n",
    "    \n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096420f5-1010-4a22-8b8c-2e955475b87d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(get_text_tokens(39))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "228ffb1d-3f57-4c88-9f14-38be37dc8f18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time, json\n",
    "from botocore.exceptions import ClientError\n",
    "sleep_on_throttling_sec = 5\n",
    "\n",
    "def benchmark(bedrock, prompt, max_tokens_to_sample, stream=True, temprature=0):\n",
    "    modelId = 'anthropic.claude-v2'\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "    \n",
    "    body = json.dumps({\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens_to_sample\": max_tokens_to_sample,\n",
    "    \"temperature\": 0,\n",
    "})\n",
    "    while True:\n",
    "        try:\n",
    "            start = time.time()\n",
    "\n",
    "            if stream:\n",
    "                response = bedrock.invoke_model_with_response_stream(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "            else:\n",
    "                response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "            #print(response)\n",
    "            \n",
    "            first_byte = None\n",
    "            if stream:\n",
    "                event_stream = response.get('body')\n",
    "                for event in event_stream:\n",
    "                    chunk = event.get('chunk')\n",
    "                    if chunk:\n",
    "                        if not first_byte:\n",
    "                            first_byte = time.time() # update the time to first byte\n",
    "                        #print(f'chunk:\\n {json.loads(chunk.get('bytes').decode())}')\n",
    "                # end of stream - check stop_reson in last chunk\n",
    "                stop_reason = json.loads(chunk.get('bytes').decode())['stop_reason']    \n",
    "                last_byte = time.time()\n",
    "            else:\n",
    "                #no streaming flow\n",
    "                first_byte = time.time()\n",
    "                last_byte = first_byte\n",
    "                response_body = json.loads(response.get('body').read())\n",
    "                stop_reason = response_body['stop_reason']\n",
    "\n",
    "            \n",
    "            # verify we got all of the intended output tokens\n",
    "            assert stop_reason == 'max_tokens', f\"stop_reason is {stop_reason} instead of 'max_tokens', this means the model generated less tokens than required.\"\n",
    "\n",
    "            duration_to_first_byte = first_byte - start\n",
    "            duration_to_last_byte = last_byte - start\n",
    "        except ClientError as err:\n",
    "            if 'Thrott' in err.response['Error']['Code']:\n",
    "                print(f'Got ThrottlingException. Sleeping {sleep_on_throttling_sec} sec and retrying.')\n",
    "                time.sleep(sleep_on_throttling_sec)\n",
    "                continue\n",
    "            raise err\n",
    "        break\n",
    "    return duration_to_first_byte, duration_to_last_byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5cd8c0a-ce24-43b8-805c-caff1fe2980f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7483198642730713, 4.039894104003906)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(bedrock, get_text_tokens(50), 100, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e5717f1-da8a-4873-ad05-7340a1177821",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'in_tokens': 50, 'out_tokens': 50, 'name': 'in=50, out=50'},\n",
       " {'in_tokens': 200, 'out_tokens': 50, 'name': 'in=200, out=50'},\n",
       " {'in_tokens': 1000, 'out_tokens': 50, 'name': 'in=1000, out=50'},\n",
       " {'in_tokens': 2000, 'out_tokens': 50, 'name': 'in=2000, out=50'},\n",
       " {'in_tokens': 4000, 'out_tokens': 50, 'name': 'in=4000, out=50'},\n",
       " {'in_tokens': 8000, 'out_tokens': 50, 'name': 'in=8000, out=50'},\n",
       " {'in_tokens': 16000, 'out_tokens': 50, 'name': 'in=16000, out=50'},\n",
       " {'in_tokens': 32000, 'out_tokens': 50, 'name': 'in=32000, out=50'},\n",
       " {'in_tokens': 64000, 'out_tokens': 50, 'name': 'in=64000, out=50'},\n",
       " {'in_tokens': 100000, 'out_tokens': 50, 'name': 'in=100000, out=50'},\n",
       " {'in_tokens': 50, 'out_tokens': 200, 'name': 'in=50, out=200'},\n",
       " {'in_tokens': 200, 'out_tokens': 200, 'name': 'in=200, out=200'},\n",
       " {'in_tokens': 1000, 'out_tokens': 200, 'name': 'in=1000, out=200'},\n",
       " {'in_tokens': 2000, 'out_tokens': 200, 'name': 'in=2000, out=200'},\n",
       " {'in_tokens': 4000, 'out_tokens': 200, 'name': 'in=4000, out=200'},\n",
       " {'in_tokens': 8000, 'out_tokens': 200, 'name': 'in=8000, out=200'},\n",
       " {'in_tokens': 16000, 'out_tokens': 200, 'name': 'in=16000, out=200'},\n",
       " {'in_tokens': 32000, 'out_tokens': 200, 'name': 'in=32000, out=200'},\n",
       " {'in_tokens': 64000, 'out_tokens': 200, 'name': 'in=64000, out=200'},\n",
       " {'in_tokens': 100000, 'out_tokens': 200, 'name': 'in=100000, out=200'},\n",
       " {'in_tokens': 50, 'out_tokens': 1000, 'name': 'in=50, out=1000'},\n",
       " {'in_tokens': 200, 'out_tokens': 1000, 'name': 'in=200, out=1000'},\n",
       " {'in_tokens': 1000, 'out_tokens': 1000, 'name': 'in=1000, out=1000'},\n",
       " {'in_tokens': 2000, 'out_tokens': 1000, 'name': 'in=2000, out=1000'},\n",
       " {'in_tokens': 4000, 'out_tokens': 1000, 'name': 'in=4000, out=1000'},\n",
       " {'in_tokens': 8000, 'out_tokens': 1000, 'name': 'in=8000, out=1000'},\n",
       " {'in_tokens': 16000, 'out_tokens': 1000, 'name': 'in=16000, out=1000'},\n",
       " {'in_tokens': 32000, 'out_tokens': 1000, 'name': 'in=32000, out=1000'},\n",
       " {'in_tokens': 64000, 'out_tokens': 1000, 'name': 'in=64000, out=1000'},\n",
       " {'in_tokens': 100000, 'out_tokens': 1000, 'name': 'in=100000, out=1000'},\n",
       " {'in_tokens': 50, 'out_tokens': 2000, 'name': 'in=50, out=2000'},\n",
       " {'in_tokens': 200, 'out_tokens': 2000, 'name': 'in=200, out=2000'},\n",
       " {'in_tokens': 1000, 'out_tokens': 2000, 'name': 'in=1000, out=2000'},\n",
       " {'in_tokens': 2000, 'out_tokens': 2000, 'name': 'in=2000, out=2000'},\n",
       " {'in_tokens': 4000, 'out_tokens': 2000, 'name': 'in=4000, out=2000'},\n",
       " {'in_tokens': 8000, 'out_tokens': 2000, 'name': 'in=8000, out=2000'},\n",
       " {'in_tokens': 16000, 'out_tokens': 2000, 'name': 'in=16000, out=2000'},\n",
       " {'in_tokens': 32000, 'out_tokens': 2000, 'name': 'in=32000, out=2000'},\n",
       " {'in_tokens': 64000, 'out_tokens': 2000, 'name': 'in=64000, out=2000'},\n",
       " {'in_tokens': 100000, 'out_tokens': 2000, 'name': 'in=100000, out=2000'},\n",
       " {'in_tokens': 50, 'out_tokens': 4000, 'name': 'in=50, out=4000'},\n",
       " {'in_tokens': 200, 'out_tokens': 4000, 'name': 'in=200, out=4000'},\n",
       " {'in_tokens': 1000, 'out_tokens': 4000, 'name': 'in=1000, out=4000'},\n",
       " {'in_tokens': 2000, 'out_tokens': 4000, 'name': 'in=2000, out=4000'},\n",
       " {'in_tokens': 4000, 'out_tokens': 4000, 'name': 'in=4000, out=4000'},\n",
       " {'in_tokens': 8000, 'out_tokens': 4000, 'name': 'in=8000, out=4000'},\n",
       " {'in_tokens': 16000, 'out_tokens': 4000, 'name': 'in=16000, out=4000'},\n",
       " {'in_tokens': 32000, 'out_tokens': 4000, 'name': 'in=32000, out=4000'},\n",
       " {'in_tokens': 64000, 'out_tokens': 4000, 'name': 'in=64000, out=4000'},\n",
       " {'in_tokens': 100000, 'out_tokens': 4000, 'name': 'in=100000, out=4000'},\n",
       " {'in_tokens': 50, 'out_tokens': 8191, 'name': 'in=50, out=8191'},\n",
       " {'in_tokens': 200, 'out_tokens': 8191, 'name': 'in=200, out=8191'},\n",
       " {'in_tokens': 1000, 'out_tokens': 8191, 'name': 'in=1000, out=8191'},\n",
       " {'in_tokens': 2000, 'out_tokens': 8191, 'name': 'in=2000, out=8191'},\n",
       " {'in_tokens': 4000, 'out_tokens': 8191, 'name': 'in=4000, out=8191'},\n",
       " {'in_tokens': 8000, 'out_tokens': 8191, 'name': 'in=8000, out=8191'},\n",
       " {'in_tokens': 16000, 'out_tokens': 8191, 'name': 'in=16000, out=8191'},\n",
       " {'in_tokens': 32000, 'out_tokens': 8191, 'name': 'in=32000, out=8191'},\n",
       " {'in_tokens': 64000, 'out_tokens': 8191, 'name': 'in=64000, out=8191'},\n",
       " {'in_tokens': 100000, 'out_tokens': 8191, 'name': 'in=100000, out=8191'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "early_break = False\n",
    "num_in_tokens_to_test = (50, 200, 1000, 2000, 4000, 8000, 16000, 32000, 64000, 100_000)\n",
    "num_out_tokens_to_test = (50, 200, 1000, 2000, 4000, 8191)\n",
    "test_scenarios = list()\n",
    "for out_tokens in num_out_tokens_to_test:\n",
    "    for in_tokens in num_in_tokens_to_test:\n",
    "        test_scenarios.append(\n",
    "            {\n",
    "                'in_tokens' : in_tokens,\n",
    "                'out_tokens' : out_tokens,\n",
    "                'name' : f'in={in_tokens}, out={out_tokens}',\n",
    "            }\n",
    "        )\n",
    "test_scenarios     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3ec07c-d0d6-423c-8b7f-32b109d02bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in test_scenarios:\n",
    "    for i in range(3): # increase to sample each use case more than once to discover jitter\n",
    "        try:\n",
    "            prompt = get_text_tokens(scenario['in_tokens'])\n",
    "            ttfb,ttlb = benchmark(bedrock, prompt, scenario['out_tokens'])\n",
    "\n",
    "            if 'durations' not in scenario: scenario['durations'] = list()\n",
    "            duration = {\n",
    "                'time-to-first-byte-seconds':  ttfb,\n",
    "                'time-to-last-byte-seconds':  ttlb,\n",
    "            }\n",
    "            scenario['durations'].append(duration)\n",
    "\n",
    "            print(f\"Scenario: [{scenario['name']}, \" + \n",
    "                  f'Duration: {pp.pformat((duration))}')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Error while processing scenario: {scenario['name']}.\")\n",
    "        if early_break:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec03cd0-a5f2-4989-b786-3f0b18e1228a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pp.pprint(test_scenarios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47494e78-7cdb-4982-b6de-af0f492d2858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52256e0e-d53c-4857-a0b9-02d883e31564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Base Python 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-base-python-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
